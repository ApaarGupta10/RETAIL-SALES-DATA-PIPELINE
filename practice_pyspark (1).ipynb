{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"rhOhbcwgppVf","executionInfo":{"status":"ok","timestamp":1754754722238,"user_tz":-330,"elapsed":14418,"user":{"displayName":"Prateek Kumar","userId":"08265699435142319276"}}},"outputs":[],"source":["# Install OpenJDK 8 (required for Spark)\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"PIjp4EIgMpDl","executionInfo":{"status":"ok","timestamp":1754754748654,"user_tz":-330,"elapsed":22460,"user":{"displayName":"Prateek Kumar","userId":"08265699435142319276"}}},"outputs":[],"source":["# Download Apache Spark 3.5.0 prebuilt with Hadoop 3\n","!wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"IoxYFn70Mrid","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754754751724,"user_tz":-330,"elapsed":147,"user":{"displayName":"Prateek Kumar","userId":"08265699435142319276"}},"outputId":"5607bdf5-3570-4834-960c-51c7f60c8bb4"},"outputs":[{"output_type":"stream","name":"stdout","text":["-rw-r--r-- 1 root root 382M Sep  9  2023 spark-3.5.0-bin-hadoop3.tgz\n"]}],"source":["# Verify Spark file\n","!ls -lh spark-3.5.0-bin-hadoop3.tgz"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"GGfpGwCiNF7i","executionInfo":{"status":"ok","timestamp":1754754757842,"user_tz":-330,"elapsed":5031,"user":{"displayName":"Prateek Kumar","userId":"08265699435142319276"}}},"outputs":[],"source":["# Extract Spark archive\n","!tar -xzf spark-3.5.0-bin-hadoop3.tgz"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112,"status":"ok","timestamp":1754754759213,"user":{"displayName":"Prateek Kumar","userId":"08265699435142319276"},"user_tz":-330},"id":"WjT4PPsWkqfx","outputId":"45cd50fe-8156-437b-aead-8f8a133302ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["bin   data\tjars\t    LICENSE   NOTICE  R\t\t RELEASE  yarn\n","conf  examples\tkubernetes  licenses  python  README.md  sbin\n"]}],"source":["# List extracted Spark files\n","!ls /content/spark-3.5.0-bin-hadoop3"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"M4eKL1EJksEn","executionInfo":{"status":"ok","timestamp":1754754773931,"user_tz":-330,"elapsed":12724,"user":{"displayName":"Prateek Kumar","userId":"08265699435142319276"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"74b1e50f-a554-4931-c1cd-4232020d0f51"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.9/33.9 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# Install Python libraries\n","!pip install -q findspark\n","!pip install -q mysql-connector-python pyspark"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"CqF5suknk3qV","executionInfo":{"status":"ok","timestamp":1754754775498,"user_tz":-330,"elapsed":20,"user":{"displayName":"Prateek Kumar","userId":"08265699435142319276"}}},"outputs":[],"source":["import os\n","\n","# Set Java and Spark environment paths\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n","\n","# Initialize findspark\n","import findspark\n","findspark.init()\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ffK8uqkolRl4","executionInfo":{"status":"ok","timestamp":1754754789919,"user_tz":-330,"elapsed":11564,"user":{"displayName":"Prateek Kumar","userId":"08265699435142319276"}}},"outputs":[],"source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().getOrCreate()\n","\n","# On yarn:\n","# spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().master(\"yarn\").getOrCreate()\n","# specify .master(\"yarn\")\n","\n","sc = spark.sparkContext"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R18QrUxCFRbq","outputId":"28e57460-0156-4741-91dc-d4ef5bc1433c","executionInfo":{"status":"ok","timestamp":1754749790484,"user_tz":-330,"elapsed":68,"user":{"displayName":"Prateek Kumar","userId":"08265699435142319276"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Error: SimpleAnalyzer() takes no arguments\n"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","from pyspark.sql.window import Window\n","from datetime import datetime\n","\n","class SimpleRetailETL:\n","    def __init__(self, app_name=\"SimpleRetailETL\"):\n","        \"\"\"Initialize Spark session\"\"\"\n","        self.spark = SparkSession.builder \\\n","            .appName(app_name) \\\n","            .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n","            .getOrCreate()\n","\n","        # Define data schema\n","        self.schema = StructType([\n","            StructField(\"InvoiceNo\", StringType(), True),\n","            StructField(\"StockCode\", StringType(), True),\n","            StructField(\"Description\", StringType(), True),\n","            StructField(\"Quantity\", IntegerType(), True),\n","            StructField(\"InvoiceDate\", StringType(), True),\n","            StructField(\"UnitPrice\", DoubleType(), True),\n","            StructField(\"CustomerID\", StringType(), True),\n","            StructField(\"Country\", StringType(), True)\n","        ])\n","        self.analyzer = SimpleAnalyzer(self.spark)\n","\n","    def load_csv_data(self, file_path):\n","        \"\"\"Load data from CSV file\"\"\"\n","        df = self.spark.read \\\n","            .option(\"header\", \"true\") \\\n","            .schema(self.schema) \\\n","            .csv(file_path)\n","\n","        print(f\"Loaded {df.count()} records from {file_path}\")\n","        return df\n","\n","    def check_data_quality(self, df):\n","        \"\"\"Basic data quality checks\"\"\"\n","        print(\"\\n=== DATA QUALITY REPORT ===\")\n","\n","        # Total records\n","        total_records = df.count()\n","        print(f\"Total records: {total_records}\")\n","\n","        # Check null values\n","        print(\"\\nNull values per column:\")\n","        for column in df.columns:\n","            null_count = df.filter(col(column).isNull()).count()\n","            if null_count > 0:\n","                print(f\"  {column}: {null_count}\")\n","\n","        # Check duplicates\n","        duplicate_count = df.count() - df.dropDuplicates().count()\n","        print(f\"\\nDuplicate records: {duplicate_count}\")\n","\n","        # Check negative values\n","        negative_qty = df.filter(col(\"Quantity\") < 0).count()\n","        negative_price = df.filter(col(\"UnitPrice\") < 0).count()\n","        print(f\"Negative quantities: {negative_qty}\")\n","        print(f\"Negative prices: {negative_price}\")\n","\n","        return df\n","\n","    def clean_and_transform(self, df):\n","        \"\"\"Clean and transform the data\"\"\"\n","        print(\"\\nCleaning and transforming data...\")\n","\n","        # Step 1: Basic cleaning\n","        df_clean = df \\\n","            .filter(col(\"InvoiceNo\").isNotNull()) \\\n","            .filter(col(\"StockCode\").isNotNull()) \\\n","            .filter(col(\"UnitPrice\") >= 0) \\\n","            .withColumn(\"Description\", trim(upper(col(\"Description\")))) \\\n","            .withColumn(\"Country\", trim(upper(col(\"Country\"))))\\\n","            .dropDuplicates()\n","\n","        # Step 2: Parse dates\n","        df_with_dates = df_clean \\\n","            .withColumn(\"InvoiceDateTime\", to_timestamp(col(\"InvoiceDate\"), \"M/d/yyyy H:mm\")) \\\n","            .withColumn(\"InvoiceDate_parsed\", to_date(col(\"InvoiceDateTime\"))) \\\n","            .withColumn(\"Year\", year(col(\"InvoiceDateTime\"))) \\\n","            .withColumn(\"Month\", month(col(\"InvoiceDateTime\"))) \\\n","            .withColumn(\"Day\", dayofmonth(col(\"InvoiceDateTime\"))) \\\n","            .withColumn(\"Hour\", hour(col(\"InvoiceDateTime\"))) \\\n","            .withColumn(\"DayOfWeek\", dayofweek(col(\"InvoiceDateTime\"))) \\\n","            .drop(\"InvoiceDate\")\n","\n","        # Step 3: Calculate business metrics\n","        df_with_metrics = df_with_dates \\\n","            .withColumn(\"TotalAmount\", col(\"Quantity\") * col(\"UnitPrice\")) \\\n","            .withColumn(\"IsReturn\", col(\"Quantity\") < 0) \\\n","            .withColumn(\"IsCancellation\", col(\"InvoiceNo\").startswith(\"C\")) \\\n","            .withColumn(\"HasCustomerID\", col(\"CustomerID\").isNotNull()) \\\n","            .withColumn(\"CustomerID_clean\",\n","                       when(col(\"CustomerID\").isNotNull(),\n","                            col(\"CustomerID\").cast(\"integer\")).otherwise(None))\n","\n","        # Step 4: Product categories\n","        df_final = df_with_metrics \\\n","            .withColumn(\"ProductCategory\",\n","                       when(col(\"StockCode\").rlike(\"^[0-9]+[A-Z]*$\"), \"Standard Product\")\n","                       .when(col(\"StockCode\") == \"POST\", \"Postage\")\n","                       .when(col(\"StockCode\") == \"D\", \"Discount\")\n","                       .when(col(\"StockCode\").rlike(\"^C[0-9]+\"), \"Cancellation\")\n","                       .otherwise(\"Other\"))\n","\n","        print(f\"Transformation complete. Final record count: {df_final.count()}\")\n","        return df_final\n","\n","    def create_summary_tables(self, df):\n","        \"\"\"Create summary tables for analysis\"\"\"\n","        print(\"\\nCreating summary tables...\")\n","\n","        # Daily sales summary\n","        daily_sales = df.filter(~col(\"IsReturn\") & ~col(\"IsCancellation\")) \\\n","            .groupBy(\"InvoiceDate_parsed\", \"Country\") \\\n","            .agg(\n","                round(sum(\"TotalAmount\"),2).alias(\"DailySales\"),\n","                sum(\"Quantity\").alias(\"ItemsSold\"),\n","                countDistinct(\"InvoiceNo\").alias(\"Orders\"),\n","                countDistinct(\"CustomerID_clean\").alias(\"Customers\")\n","            ) \\\n","            .orderBy(\"InvoiceDate_parsed\")\n","\n","        # Customer summary\n","        customer_summary = df.filter(col(\"HasCustomerID\") & ~col(\"IsCancellation\")) \\\n","            .groupBy(\"CustomerID_clean\", \"Country\") \\\n","            .agg(\n","                round(sum(\"TotalAmount\"),2).alias(\"TotalSpent\"),\n","                sum(\"Quantity\").alias(\"TotalItems\"),\n","                countDistinct(\"InvoiceNo\").alias(\"TotalOrders\"),\n","                min(\"InvoiceDateTime\").alias(\"FirstPurchase\"),\n","                max(\"InvoiceDateTime\").alias(\"LastPurchase\")\n","            )\n","\n","        # Product performance\n","        product_summary = df.filter(~col(\"IsCancellation\")) \\\n","            .groupBy(\"StockCode\", \"Description\") \\\n","            .agg(\n","                sum(when(~col(\"IsReturn\"), col(\"TotalAmount\")).otherwise(0)).alias(\"Revenue\"),\n","                sum(when(~col(\"IsReturn\"), col(\"Quantity\")).otherwise(0)).alias(\"UnitsSold\"),\n","                sum(when(col(\"IsReturn\"), abs(col(\"Quantity\"))).otherwise(0)).alias(\"UnitsReturned\"),\n","                countDistinct(\"InvoiceNo\").alias(\"OrderCount\")\n","            ) \\\n","            .orderBy(desc(\"Revenue\"))\n","\n","        # Country performance\n","        country_summary = df.filter(~col(\"IsCancellation\")) \\\n","            .groupBy(\"Country\") \\\n","            .agg(\n","                sum(when(~col(\"IsReturn\"), col(\"TotalAmount\")).otherwise(0)).alias(\"Revenue\"),\n","                countDistinct(\"CustomerID_clean\").alias(\"Customers\"),\n","                countDistinct(\"InvoiceNo\").alias(\"Orders\")\n","            ) \\\n","            .orderBy(desc(\"Revenue\"))\n","\n","        summaries = {\n","            \"daily_sales\": daily_sales,\n","            \"customer_summary\": customer_summary,\n","            \"product_summary\": product_summary,\n","            \"country_summary\": country_summary\n","        }\n","\n","        print(\"Summary tables created successfully!\")\n","        return summaries\n","\n","    def save_data(self, df, summaries, output_path):\n","        \"\"\"Save transformed data and summaries\"\"\"\n","        print(f\"\\nSaving data to {output_path}...\")\n","\n","        # Save main dataset\n","        df.write.mode(\"overwrite\").parquet(f\"{output_path}/transformed_data\")\n","\n","        # Save summary tables\n","        for name, summary_df in summaries.items():\n","            summary_df.write.mode(\"overwrite\").parquet(f\"{output_path}/summaries/{name}\")\n","\n","        print(\"Data saved successfully!\")\n","\n","    def show_sample_data(self, df, rows=10):\n","        \"\"\"Display sample data\"\"\"\n","        print(f\"\\nSample data ({rows} rows):\")\n","        df.show(rows, truncate=False)\n","\n","        print(\"\\nData schema:\")\n","        df.printSchema()\n","\n","    def show_summary_stats(self, summaries):\n","        \"\"\"Display summary statistics\"\"\"\n","        print(\"\\n=== SUMMARY STATISTICS ===\")\n","\n","        for name, summary_df in summaries.items():\n","            print(f\"\\n{name.upper().replace('_', ' ')}:\")\n","            print(\"-\" * 40)\n","            summary_df.show(5)\n","\n","    def run_complete_pipeline(self, input_path, output_path):\n","        \"\"\"Run the complete ETL pipeline\"\"\"\n","        start_time = datetime.now()\n","        print(\"Starting ETL Pipeline...\")\n","        print(f\"Input: {input_path}\")\n","        print(f\"Output: {output_path}\")\n","\n","        # Step 1: Load data\n","        raw_df = self.load_csv_data(input_path)\n","\n","        # Step 2: Quality checks\n","        raw_df = self.check_data_quality(raw_df)\n","\n","        # Step 3: Transform data\n","        transformed_df = self.clean_and_transform(raw_df)\n","\n","        # Step 4: Create summaries\n","        summaries = self.create_summary_tables(transformed_df)\n","\n","        # Step 5: Save data\n","        self.save_data(transformed_df, summaries, output_path)\n","\n","        # Show results\n","        self.show_sample_data(transformed_df)\n","        self.show_summary_stats(summaries)\n","\n","        # Pipeline completion\n","        end_time = datetime.now()\n","        duration = end_time - start_time\n","\n","        print(f\"\\n=== PIPELINE COMPLETED ===\")\n","        print(f\"Duration: {duration}\")\n","        print(f\"Records processed: {transformed_df.count()}\")\n","\n","        return transformed_df, summaries\n","\n","    def stop(self):\n","        \"\"\"Stop Spark session\"\"\"\n","        self.spark.stop()\n","        print(\"Spark session stopped.\")\n","\n","# Simple usage example\n","def main():\n","    etl = None\n","    try:\n","        # Create ETL instance\n","        etl = SimpleRetailETL()\n","\n","        # Set file paths\n","        input_file = \"/content/Online Retail.csv\"  # Change to your file path\n","        output_folder = \"/content/retail_output\"   # Change to your output path\n","\n","        # Run the pipeline\n","        transformed_data, summaries = etl.run_complete_pipeline(input_file, output_folder)\n","\n","        print(\"\\nETL Pipeline completed successfully!\")\n","\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","    finally:\n","        if etl:\n","            etl.stop()\n","\n","# Context manager for automatic cleanup\n","'''class ETLContext:\n","    def __init__(self, app_name=\"SimpleRetailETL\"):\n","        self.app_name = app_name\n","        self.etl = None\n","\n","    def __enter__(self):\n","        self.etl = SimpleRetailETL(self.app_name)\n","        return self.etl\n","\n","    def __exit__(self, exc_type, exc_val, exc_tb):\n","        if self.etl:\n","            self.etl.stop()'''\n","\n","# Recommended usage with context manager\n","'''def run_with_context():\n","    \"\"\"Recommended way to run ETL with automatic cleanup\"\"\"\n","    input_file = \"/content/Online Retail.csv\"\n","    output_folder = \"/content/retail_output\"\n","\n","    try:\n","        with ETLContext() as etl:\n","            transformed_data, summaries = etl.run_complete_pipeline(input_file, output_folder)\n","            print(\"Pipeline completed successfully!\")\n","\n","    except Exception as e:\n","        print(f\"Pipeline failed: {e}\")'''\n","\n","# Additional analysis functions\n","class SimpleAnalyzer:\n","    \"\"\"Simple data analysis functions\"\"\"\n","\n","    @staticmethod\n","    def monthly_trends(spark, data_path):\n","        \"\"\"Analyze monthly sales trends\"\"\"\n","        df = spark.read.parquet(data_path)\n","\n","        monthly_sales = df.filter(~col(\"IsReturn\")) \\\n","            .groupBy(\"Year\", \"Month\") \\\n","            .agg(\n","                sum(\"TotalAmount\").alias(\"MonthlySales\"),\n","                countDistinct(\"CustomerID_clean\").alias(\"ActiveCustomers\")\n","            ) \\\n","            .orderBy(\"Year\", \"Month\")\n","\n","        return monthly_sales\n","\n","    @staticmethod\n","    def top_customers(spark, customer_summary_path, top_n=10):\n","        \"\"\"Find top customers by spending\"\"\"\n","        df = spark.read.parquet(customer_summary_path)\n","\n","        top_customers = df.orderBy(desc(\"TotalSpent\")).limit(top_n)\n","        return top_customers\n","\n","    @staticmethod\n","    def top_products(spark, product_summary_path, top_n=10):\n","        \"\"\"Find top products by revenue\"\"\"\n","        df = spark.read.parquet(product_summary_path)\n","\n","        top_products = df.orderBy(desc(\"Revenue\")).limit(top_n)\n","        return top_products\n","\n","if __name__ == \"__main__\":\n","    # Run the main function\n","    main()\n","\n","    # Or use the context manager approach (recommended)\n","    #run_with_context()"]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","from pyspark.sql.window import Window\n","from datetime import datetime\n","\n","class SimpleRetailETL:\n","    def __init__(self, app_name=\"SimpleRetailETL\"):\n","        \"\"\"Initialize Spark session\"\"\"\n","        self.spark = SparkSession.builder \\\n","            .appName(app_name) \\\n","            .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n","            .getOrCreate()\n","\n","        # Define data schema\n","        self.schema = StructType([\n","            StructField(\"InvoiceNo\", StringType(), True),\n","            StructField(\"StockCode\", StringType(), True),\n","            StructField(\"Description\", StringType(), True),\n","            StructField(\"Quantity\", IntegerType(), True),\n","            StructField(\"InvoiceDate\", StringType(), True),\n","            StructField(\"UnitPrice\", DoubleType(), True),\n","            StructField(\"CustomerID\", StringType(), True),\n","            StructField(\"Country\", StringType(), True)\n","        ])\n","\n","        # Initialize analyzer\n","        self.analyzer = SimpleAnalyzer(self.spark)\n","\n","    def load_csv_data(self, file_path):\n","        \"\"\"Load data from CSV file\"\"\"\n","        df = self.spark.read \\\n","            .option(\"header\", \"true\") \\\n","            .schema(self.schema) \\\n","            .csv(file_path)\n","\n","        print(f\"Loaded {df.count()} records from {file_path}\")\n","        return df\n","\n","    def check_data_quality(self, df):\n","        \"\"\"Basic data quality checks\"\"\"\n","        print(\"\\n=== DATA QUALITY REPORT ===\")\n","\n","        # Total records\n","        total_records = df.count()\n","        print(f\"Total records: {total_records}\")\n","\n","        # Check null values\n","        print(\"\\nNull values per column:\")\n","        for column in df.columns:\n","            null_count = df.filter(col(column).isNull()).count()\n","            if null_count > 0:\n","                print(f\"  {column}: {null_count}\")\n","\n","        # Check duplicates\n","        duplicate_count = df.count() - df.dropDuplicates().count()\n","        print(f\"\\nDuplicate records: {duplicate_count}\")\n","\n","        # Check negative values\n","        negative_qty = df.filter(col(\"Quantity\") < 0).count()\n","        negative_price = df.filter(col(\"UnitPrice\") < 0).count()\n","        print(f\"Negative quantities: {negative_qty}\")\n","        print(f\"Negative prices: {negative_price}\")\n","\n","        return df\n","\n","    def clean_and_transform(self, df):\n","        \"\"\"Clean and transform the data\"\"\"\n","        print(\"\\nCleaning and transforming data...\")\n","\n","        # Step 1: Basic cleaning\n","        df_clean = df \\\n","            .filter(col(\"InvoiceNo\").isNotNull()) \\\n","            .filter(col(\"StockCode\").isNotNull()) \\\n","            .filter(col(\"UnitPrice\") >= 0) \\\n","            .withColumn(\"Description\", trim(upper(col(\"Description\")))) \\\n","            .withColumn(\"Country\", trim(upper(col(\"Country\"))))\\\n","            .dropDuplicates()\n","\n","        # Step 2: Parse dates\n","        df_with_dates = df_clean \\\n","            .withColumn(\"InvoiceDateTime\", to_timestamp(col(\"InvoiceDate\"), \"M/d/yyyy H:mm\")) \\\n","            .withColumn(\"InvoiceDate_parsed\", to_date(col(\"InvoiceDateTime\"))) \\\n","            .withColumn(\"Year\", year(col(\"InvoiceDateTime\"))) \\\n","            .withColumn(\"Month\", month(col(\"InvoiceDateTime\"))) \\\n","            .withColumn(\"Day\", dayofmonth(col(\"InvoiceDateTime\"))) \\\n","            .withColumn(\"Hour\", hour(col(\"InvoiceDateTime\"))) \\\n","            .withColumn(\"DayOfWeek\", dayofweek(col(\"InvoiceDateTime\"))) \\\n","            .drop(\"InvoiceDate\")\n","\n","        # Step 3: Calculate business metrics\n","        df_with_metrics = df_with_dates \\\n","            .withColumn(\"TotalAmount\", col(\"Quantity\") * col(\"UnitPrice\")) \\\n","            .withColumn(\"IsReturn\", col(\"Quantity\") < 0) \\\n","            .withColumn(\"IsCancellation\", col(\"InvoiceNo\").startswith(\"C\")) \\\n","            .withColumn(\"HasCustomerID\", col(\"CustomerID\").isNotNull()) \\\n","            .withColumn(\"CustomerID_clean\",\n","                       when(col(\"CustomerID\").isNotNull(),\n","                            col(\"CustomerID\").cast(\"integer\")).otherwise(None))\n","\n","        # Step 4: Product categories\n","        df_final = df_with_metrics \\\n","            .withColumn(\"ProductCategory\",\n","                       when(col(\"StockCode\").rlike(\"^[0-9]+[A-Z]*$\"), \"Standard Product\")\n","                       .when(col(\"StockCode\") == \"POST\", \"Postage\")\n","                       .when(col(\"StockCode\") == \"D\", \"Discount\")\n","                       .when(col(\"StockCode\").rlike(\"^C[0-9]+\"), \"Cancellation\")\n","                       .otherwise(\"Other\"))\n","\n","        print(f\"Transformation complete. Final record count: {df_final.count()}\")\n","        return df_final\n","\n","    def create_summary_tables(self, df):\n","        \"\"\"Create summary tables for analysis\"\"\"\n","        print(\"\\nCreating summary tables...\")\n","\n","        # Daily sales summary\n","        daily_sales = df.filter(~col(\"IsReturn\") & ~col(\"IsCancellation\")) \\\n","            .groupBy(\"InvoiceDate_parsed\", \"Country\") \\\n","            .agg(\n","                round(sum(\"TotalAmount\"),2).alias(\"DailySales\"),\n","                sum(\"Quantity\").alias(\"ItemsSold\"),\n","                countDistinct(\"InvoiceNo\").alias(\"Orders\"),\n","                countDistinct(\"CustomerID_clean\").alias(\"Customers\")\n","            ) \\\n","            .orderBy(\"InvoiceDate_parsed\")\n","\n","        # Customer summary\n","        customer_summary = df.filter(col(\"HasCustomerID\") & ~col(\"IsCancellation\")) \\\n","            .groupBy(\"CustomerID_clean\", \"Country\") \\\n","            .agg(\n","                round(sum(\"TotalAmount\"),2).alias(\"TotalSpent\"),\n","                sum(\"Quantity\").alias(\"TotalItems\"),\n","                countDistinct(\"InvoiceNo\").alias(\"TotalOrders\"),\n","                min(\"InvoiceDateTime\").alias(\"FirstPurchase\"),\n","                max(\"InvoiceDateTime\").alias(\"LastPurchase\")\n","            )\n","\n","        # Product performance\n","        product_summary = df.filter(~col(\"IsCancellation\")) \\\n","            .groupBy(\"StockCode\", \"Description\") \\\n","            .agg(\n","                sum(when(~col(\"IsReturn\"), col(\"TotalAmount\")).otherwise(0)).alias(\"Revenue\"),\n","                sum(when(~col(\"IsReturn\"), col(\"Quantity\")).otherwise(0)).alias(\"UnitsSold\"),\n","                sum(when(col(\"IsReturn\"), abs(col(\"Quantity\"))).otherwise(0)).alias(\"UnitsReturned\"),\n","                countDistinct(\"InvoiceNo\").alias(\"OrderCount\")\n","            ) \\\n","            .orderBy(desc(\"Revenue\"))\n","\n","        # Country performance\n","        country_summary = df.filter(~col(\"IsCancellation\")) \\\n","            .groupBy(\"Country\") \\\n","            .agg(\n","                sum(when(~col(\"IsReturn\"), col(\"TotalAmount\")).otherwise(0)).alias(\"Revenue\"),\n","                countDistinct(\"CustomerID_clean\").alias(\"Customers\"),\n","                countDistinct(\"InvoiceNo\").alias(\"Orders\")\n","            ) \\\n","            .orderBy(desc(\"Revenue\"))\n","\n","        summaries = {\n","            \"daily_sales\": daily_sales,\n","            \"customer_summary\": customer_summary,\n","            \"product_summary\": product_summary,\n","            \"country_summary\": country_summary\n","        }\n","\n","        print(\"Summary tables created successfully!\")\n","        return summaries\n","\n","    def save_data(self, df, summaries, output_path):\n","        \"\"\"Save transformed data and summaries\"\"\"\n","        print(f\"\\nSaving data to {output_path}...\")\n","\n","        # Save main dataset\n","        df.write.mode(\"overwrite\").parquet(f\"{output_path}/transformed_data\")\n","\n","        # Save summary tables\n","        for name, summary_df in summaries.items():\n","            summary_df.write.mode(\"overwrite\").parquet(f\"{output_path}/summaries/{name}\")\n","\n","        print(\"Data saved successfully!\")\n","\n","    def show_sample_data(self, df, rows=10):\n","        \"\"\"Display sample data\"\"\"\n","        print(f\"\\nSample data ({rows} rows):\")\n","        df.show(rows, truncate=False)\n","\n","        print(\"\\nData schema:\")\n","        df.printSchema()\n","\n","    def show_summary_stats(self, summaries):\n","        \"\"\"Display summary statistics\"\"\"\n","        print(\"\\n=== SUMMARY STATISTICS ===\")\n","\n","        for name, summary_df in summaries.items():\n","            print(f\"\\n{name.upper().replace('_', ' ')}:\")\n","            print(\"-\" * 40)\n","            summary_df.show(5)\n","\n","    def run_complete_pipeline(self, input_path, output_path):\n","        \"\"\"Run the complete ETL pipeline with analysis\"\"\"\n","        start_time = datetime.now()\n","        print(\"Starting ETL Pipeline...\")\n","        print(f\"Input: {input_path}\")\n","        print(f\"Output: {output_path}\")\n","\n","        # Step 1: Load data\n","        raw_df = self.load_csv_data(input_path)\n","\n","        # Step 2: Quality checks\n","        raw_df = self.check_data_quality(raw_df)\n","\n","        # Step 3: Transform data\n","        transformed_df = self.clean_and_transform(raw_df)\n","\n","        # Step 4: Create summaries\n","        summaries = self.create_summary_tables(transformed_df)\n","\n","        # Step 5: Save data\n","        self.save_data(transformed_df, summaries, output_path)\n","\n","        # Step 6: Show basic results\n","        self.show_sample_data(transformed_df)\n","        self.show_summary_stats(summaries)\n","\n","        # Step 7: Run advanced analysis\n","        print(\"\\n\" + \"=\"*50)\n","        print(\"RUNNING ADVANCED ANALYSIS\")\n","        print(\"=\"*50)\n","\n","        analysis_results = self.analyzer.run_comprehensive_analysis(\n","            transformed_df,\n","            summaries,\n","            output_path\n","        )\n","\n","        # Pipeline completion\n","        end_time = datetime.now()\n","        duration = end_time - start_time\n","\n","        print(f\"\\n=== PIPELINE COMPLETED ===\")\n","        print(f\"Duration: {duration}\")\n","        print(f\"Records processed: {transformed_df.count()}\")\n","\n","        return transformed_df, summaries, analysis_results\n","\n","    def stop(self):\n","        \"\"\"Stop Spark session\"\"\"\n","        self.spark.stop()\n","        print(\"Spark session stopped.\")\n","\n","\n","class SimpleAnalyzer:\n","    \"\"\"Enhanced data analysis class integrated with ETL pipeline\"\"\"\n","\n","    def __init__(self, spark_session):\n","        self.spark = spark_session\n","\n","    def monthly_trends(self, df):\n","        \"\"\"Analyze monthly sales trends\"\"\"\n","        print(\"\\n--- MONTHLY SALES TRENDS ---\")\n","\n","        monthly_sales = df.filter(~col(\"IsReturn\") & ~col(\"IsCancellation\")) \\\n","            .groupBy(\"Year\", \"Month\") \\\n","            .agg(\n","                round(sum(\"TotalAmount\"), 2).alias(\"MonthlySales\"),\n","                countDistinct(\"CustomerID_clean\").alias(\"ActiveCustomers\"),\n","                countDistinct(\"InvoiceNo\").alias(\"Orders\"),\n","                sum(\"Quantity\").alias(\"ItemsSold\")\n","            ) \\\n","            .withColumn(\"MonthYear\", concat(col(\"Year\"), lit(\"-\"),\n","                       lpad(col(\"Month\"), 2, \"0\"))) \\\n","            .orderBy(\"Year\", \"Month\")\n","\n","        print(\"Monthly sales performance:\")\n","        monthly_sales.show(12)\n","\n","\n","    def top_customers(self, customer_summary, top_n=10):\n","        \"\"\"Find top customers by spending\"\"\"\n","        print(f\"\\n--- TOP {top_n} CUSTOMERS BY SPENDING ---\")\n","\n","        top_customers = customer_summary.orderBy(desc(\"TotalSpent\")).limit(top_n)\n","\n","        print(\"Top customers:\")\n","        top_customers.show(top_n, truncate=False)\n","\n","\n","    def top_products(self, product_summary, top_n=10):\n","        \"\"\"Find top products by revenue\"\"\"\n","        print(f\"\\n--- TOP {top_n} PRODUCTS BY REVENUE ---\")\n","\n","        top_products = product_summary.orderBy(desc(\"Revenue\")).limit(top_n)\n","\n","        print(\"Top products:\")\n","        top_products.show(top_n, truncate=False)\n","\n","        # Product analysis\n","        total_products = product_summary.count()\n","\n","        product_performance = product_summary \\\n","            .withColumn(\"ReturnRate\",\n","                       round(col(\"UnitsReturned\") /\n","                            (col(\"UnitsSold\") + col(\"UnitsReturned\")) * 100, 2)) \\\n","            .withColumn(\"PerformanceTier\",\n","                       when(col(\"Revenue\") >= 10000, \"Top Performer\")\n","                       .when(col(\"Revenue\") >= 1000, \"Good Performer\")\n","                       .otherwise(\"Low Performer\"))\n","\n","        performance_summary = product_performance \\\n","            .groupBy(\"PerformanceTier\") \\\n","            .agg(\n","                count(\"*\").alias(\"ProductCount\"),\n","                round(sum(\"Revenue\"), 2).alias(\"TotalRevenue\"),\n","                round(avg(\"ReturnRate\"), 2).alias(\"AvgReturnRate\")\n","            ) \\\n","            .withColumn(\"ProductPercentage\",\n","                       round(col(\"ProductCount\") / total_products * 100, 2))\n","\n","        print(\"\\nProduct performance tiers:\")\n","        performance_summary.show()\n","\n","        return top_products, product_performance\n","\n","    def country_analysis(self, country_summary):\n","        \"\"\"Analyze performance by country\"\"\"\n","        print(\"\\n--- COUNTRY PERFORMANCE ANALYSIS ---\")\n","\n","        print(\"All countries performance:\")\n","        country_summary.show()\n","\n","        # Country insights\n","        country_insights = country_summary \\\n","            .withColumn(\"RevenuePerCustomer\",\n","                       round(col(\"Revenue\") / col(\"Customers\"), 2)) \\\n","            .withColumn(\"RevenuePerOrder\",\n","                       round(col(\"Revenue\") / col(\"Orders\"), 2)) \\\n","            .orderBy(desc(\"Revenue\"))\n","\n","        print(\"\\nCountry insights (Revenue per customer and order):\")\n","        country_insights.show()\n","\n","        return country_insights\n","\n","\n","\n","\n","    def save_analysis_results(self, analysis_results, output_path):\n","        \"\"\"Save analysis results to parquet files\"\"\"\n","        print(f\"\\nSaving analysis results to {output_path}/analysis/...\")\n","\n","        try:\n","            for name, df in analysis_results.items():\n","                if df is not None:\n","                    df.write.mode(\"overwrite\").parquet(f\"{output_path}/analysis/{name}\")\n","            print(\"Analysis results saved successfully!\")\n","        except Exception as e:\n","            print(f\"Error saving analysis results: {e}\")\n","\n","    def run_comprehensive_analysis(self, df, summaries, output_path):\n","        \"\"\"Run all analysis functions\"\"\"\n","        analysis_results = {}\n","\n","        try:\n","            # Monthly trends\n","            monthly_sales = self.monthly_trends(df)\n","            analysis_results[\"monthly_trends\"] = monthly_sales\n","\n","            # Top customers\n","            top_customers = self.top_customers(summaries[\"customer_summary\"])\n","            analysis_results[\"top_customers\"] = top_customers\n","\n","            # Top products\n","            top_products, product_performance = self.top_products(summaries[\"product_summary\"])\n","            analysis_results[\"top_products\"] = top_products\n","            analysis_results[\"product_performance\"] = product_performance\n","\n","            # Country analysis\n","            country_insights = self.country_analysis(summaries[\"country_summary\"])\n","            analysis_results[\"country_insights\"] = country_insights\n","\n","            # Save analysis results\n","            self.save_analysis_results(analysis_results, output_path)\n","\n","            print(\"\\n\" + \"=\"*50)\n","            print(\"COMPREHENSIVE ANALYSIS COMPLETED!\")\n","            print(\"=\"*50)\n","\n","        except Exception as e:\n","            print(f\"Error during analysis: {e}\")\n","\n","        return analysis_results\n","\n","\n","# Context manager for automatic cleanup\n","class ETLContext:\n","    def __init__(self, app_name=\"SimpleRetailETL\"):\n","        self.app_name = app_name\n","        self.etl = None\n","\n","    def __enter__(self):\n","        self.etl = SimpleRetailETL(self.app_name)\n","        return self.etl\n","\n","    def __exit__(self, exc_type, exc_val, exc_tb):\n","        if self.etl:\n","            self.etl.stop()\n","\n","\n","def main():\n","    \"\"\"Main function to run the complete ETL and analysis pipeline\"\"\"\n","    etl = None\n","    try:\n","        # Create ETL instance\n","        etl = SimpleRetailETL()\n","\n","        # Set file paths\n","        input_file = \"/content/Online Retail.csv\"  # Change to your file path\n","        output_folder = \"/content/retail_output\"   # Change to your output path\n","\n","        # Run the complete pipeline with analysis\n","        transformed_data, summaries, analysis_results = etl.run_complete_pipeline(\n","            input_file, output_folder\n","        )\n","\n","        print(\"\\n\" + \"=\"*60)\n","        print(\"ETL PIPELINE AND ANALYSIS COMPLETED SUCCESSFULLY!\")\n","        print(\"=\"*60)\n","        print(f\"✓ Transformed data saved to: {output_folder}/transformed_data\")\n","        print(f\"✓ Summary tables saved to: {output_folder}/summaries/\")\n","        print(f\"✓ Analysis results saved to: {output_folder}/analysis/\")\n","\n","    except Exception as e:\n","        print(f\"Pipeline Error: {e}\")\n","\n","    finally:\n","        if etl:\n","            etl.stop()\n","\n","\n","def run_with_context():\n","    \"\"\"Recommended way to run ETL with automatic cleanup\"\"\"\n","    input_file = \"/content/Online Retail.csv\"\n","    output_folder = \"/content/retail_output\"\n","\n","    try:\n","        with ETLContext() as etl:\n","            transformed_data, summaries, analysis_results = etl.run_complete_pipeline(\n","                input_file, output_folder\n","            )\n","            print(\"\\nPipeline and analysis completed successfully!\")\n","\n","    except Exception as e:\n","        print(f\"Pipeline failed: {e}\")\n","\n","\n","if __name__ == \"__main__\":\n","    # Run the main function\n","    main()\n","\n","    # Or use the context manager approach (recommended)\n","    # run_with_context()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aXQ93VkFPhWL","executionInfo":{"status":"ok","timestamp":1754755751845,"user_tz":-330,"elapsed":151382,"user":{"displayName":"Prateek Kumar","userId":"08265699435142319276"}},"outputId":"4d563de2-9b8c-4147-e551-5c3c6508bcd4"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting ETL Pipeline...\n","Input: /content/Online Retail.csv\n","Output: /content/retail_output\n","Loaded 541909 records from /content/Online Retail.csv\n","\n","=== DATA QUALITY REPORT ===\n","Total records: 541909\n","\n","Null values per column:\n","  Description: 1454\n","  CustomerID: 135080\n","\n","Duplicate records: 5268\n","Negative quantities: 10624\n","Negative prices: 2\n","\n","Cleaning and transforming data...\n","Transformation complete. Final record count: 536639\n","\n","Creating summary tables...\n","Summary tables created successfully!\n","\n","Saving data to /content/retail_output...\n","Data saved successfully!\n","\n","Sample data (10 rows):\n","+---------+---------+----------------------------------+--------+---------+----------+--------------+-------------------+------------------+----+-----+---+----+---------+------------------+--------+--------------+-------------+----------------+----------------+\n","|InvoiceNo|StockCode|Description                       |Quantity|UnitPrice|CustomerID|Country       |InvoiceDateTime    |InvoiceDate_parsed|Year|Month|Day|Hour|DayOfWeek|TotalAmount       |IsReturn|IsCancellation|HasCustomerID|CustomerID_clean|ProductCategory |\n","+---------+---------+----------------------------------+--------+---------+----------+--------------+-------------------+------------------+----+-----+---+----+---------+------------------+--------+--------------+-------------+----------------+----------------+\n","|536367   |84969    |BOX OF 6 ASSORTED COLOUR TEASPOONS|6       |4.25     |13047     |UNITED KINGDOM|2010-12-01 08:34:00|2010-12-01        |2010|12   |1  |8   |4        |25.5              |false   |false         |true         |13047           |Standard Product|\n","|536392   |22338    |STAR DECORATION PAINTED ZINC      |24      |0.65     |13705     |UNITED KINGDOM|2010-12-01 10:29:00|2010-12-01        |2010|12   |1  |10  |4        |15.600000000000001|false   |false         |true         |13705           |Standard Product|\n","|536401   |22382    |LUNCH BAG SPACEBOY DESIGN         |2       |1.65     |15862     |UNITED KINGDOM|2010-12-01 11:21:00|2010-12-01        |2010|12   |1  |11  |4        |3.3               |false   |false         |true         |15862           |Standard Product|\n","|536409   |21676    |FLOWERS  STICKERS                 |6       |0.85     |17908     |UNITED KINGDOM|2010-12-01 11:45:00|2010-12-01        |2010|12   |1  |11  |4        |5.1               |false   |false         |true         |17908           |Standard Product|\n","|536412   |22144    |CHRISTMAS CRAFT LITTLE FRIENDS    |2       |2.1      |17920     |UNITED KINGDOM|2010-12-01 11:49:00|2010-12-01        |2010|12   |1  |11  |4        |4.2               |false   |false         |true         |17920           |Standard Product|\n","|536522   |84997D   |PINK 3 PIECE POLKADOT CUTLERY SET |1       |3.75     |15012     |UNITED KINGDOM|2010-12-01 12:49:00|2010-12-01        |2010|12   |1  |12  |4        |3.75              |false   |false         |true         |15012           |Standard Product|\n","|536522   |47599B   |BLUE PARTY BAGS                   |1       |2.1      |15012     |UNITED KINGDOM|2010-12-01 12:49:00|2010-12-01        |2010|12   |1  |12  |4        |2.1               |false   |false         |true         |15012           |Standard Product|\n","|536528   |22812    |PACK 3 BOXES CHRISTMAS PANNETONE  |3       |1.95     |15525     |UNITED KINGDOM|2010-12-01 13:17:00|2010-12-01        |2010|12   |1  |13  |4        |5.85              |false   |false         |true         |15525           |Standard Product|\n","|536557   |22451    |SILK PURSE BABUSHKA RED           |3       |3.35     |17841     |UNITED KINGDOM|2010-12-01 14:41:00|2010-12-01        |2010|12   |1  |14  |4        |10.05             |false   |false         |true         |17841           |Standard Product|\n","|536563   |22941    |CHRISTMAS LIGHTS 10 REINDEER      |1       |8.5      |17760     |UNITED KINGDOM|2010-12-01 15:08:00|2010-12-01        |2010|12   |1  |15  |4        |8.5               |false   |false         |true         |17760           |Standard Product|\n","+---------+---------+----------------------------------+--------+---------+----------+--------------+-------------------+------------------+----+-----+---+----+---------+------------------+--------+--------------+-------------+----------------+----------------+\n","only showing top 10 rows\n","\n","\n","Data schema:\n","root\n"," |-- InvoiceNo: string (nullable = true)\n"," |-- StockCode: string (nullable = true)\n"," |-- Description: string (nullable = true)\n"," |-- Quantity: integer (nullable = true)\n"," |-- UnitPrice: double (nullable = true)\n"," |-- CustomerID: string (nullable = true)\n"," |-- Country: string (nullable = true)\n"," |-- InvoiceDateTime: timestamp (nullable = true)\n"," |-- InvoiceDate_parsed: date (nullable = true)\n"," |-- Year: integer (nullable = true)\n"," |-- Month: integer (nullable = true)\n"," |-- Day: integer (nullable = true)\n"," |-- Hour: integer (nullable = true)\n"," |-- DayOfWeek: integer (nullable = true)\n"," |-- TotalAmount: double (nullable = true)\n"," |-- IsReturn: boolean (nullable = true)\n"," |-- IsCancellation: boolean (nullable = true)\n"," |-- HasCustomerID: boolean (nullable = false)\n"," |-- CustomerID_clean: integer (nullable = true)\n"," |-- ProductCategory: string (nullable = false)\n","\n","\n","=== SUMMARY STATISTICS ===\n","\n","DAILY SALES:\n","----------------------------------------\n","+------------------+--------------+----------+---------+------+---------+\n","|InvoiceDate_parsed|       Country|DailySales|ItemsSold|Orders|Customers|\n","+------------------+--------------+----------+---------+------+---------+\n","|        2010-12-01|       GERMANY|    261.48|      157|     1|        1|\n","|        2010-12-01|        FRANCE|    855.86|      449|     1|        1|\n","|        2010-12-01|          EIRE|    555.38|      243|     2|        1|\n","|        2010-12-01|UNITED KINGDOM|  54634.08|    24001|   129|       89|\n","|        2010-12-01|        NORWAY|   1919.14|     1852|     1|        1|\n","+------------------+--------------+----------+---------+------+---------+\n","only showing top 5 rows\n","\n","\n","CUSTOMER SUMMARY:\n","----------------------------------------\n","+----------------+--------------+----------+----------+-----------+-------------------+-------------------+\n","|CustomerID_clean|       Country|TotalSpent|TotalItems|TotalOrders|      FirstPurchase|       LastPurchase|\n","+----------------+--------------+----------+----------+-----------+-------------------+-------------------+\n","|           15505|UNITED KINGDOM|   3610.96|      2390|          5|2011-07-07 13:33:00|2011-10-18 07:56:00|\n","|           16892|UNITED KINGDOM|    518.19|       236|          5|2011-06-09 11:35:00|2011-12-08 13:18:00|\n","|           15152|UNITED KINGDOM|   4745.69|      2704|         13|2011-06-05 15:36:00|2011-11-30 12:32:00|\n","|           18161|UNITED KINGDOM|   1618.69|       812|          5|2011-01-24 11:56:00|2011-11-24 16:40:00|\n","|           12662|       GERMANY|   3849.78|      2058|         11|2010-12-01 13:04:00|2011-12-09 11:59:00|\n","+----------------+--------------+----------+----------+-----------+-------------------+-------------------+\n","only showing top 5 rows\n","\n","\n","PRODUCT SUMMARY:\n","----------------------------------------\n","+---------+--------------------+------------------+---------+-------------+----------+\n","|StockCode|         Description|           Revenue|UnitsSold|UnitsReturned|OrderCount|\n","+---------+--------------------+------------------+---------+-------------+----------+\n","|      DOT|      DOTCOM POSTAGE|206248.77000000005|      708|            0|       708|\n","|    22423|REGENCY CAKESTAND...|174156.53999999963|    13862|            0|      1989|\n","|    23843|PAPER CRAFT , LIT...|          168469.6|    80995|            0|         1|\n","|   85123A|WHITE HANGING HEA...|104284.23999999971|    37584|            0|      2193|\n","|    47566|       PARTY BUNTING| 99445.23000000027|    18287|            0|      1686|\n","+---------+--------------------+------------------+---------+-------------+----------+\n","only showing top 5 rows\n","\n","\n","COUNTRY SUMMARY:\n","----------------------------------------\n","+--------------+------------------+---------+------+\n","|       Country|           Revenue|Customers|Orders|\n","+--------------+------------------+---------+------+\n","|UNITED KINGDOM|  9001744.09399904|     3921| 20120|\n","|   NETHERLANDS| 285446.3399999995|        9|    95|\n","|          EIRE| 283140.5199999988|        3|   288|\n","|       GERMANY|228678.40000000005|       94|   457|\n","|        FRANCE|         209625.37|       87|   392|\n","+--------------+------------------+---------+------+\n","only showing top 5 rows\n","\n","\n","==================================================\n","RUNNING ADVANCED ANALYSIS\n","==================================================\n","\n","--- MONTHLY SALES TRENDS ---\n","Monthly sales performance:\n","+----+-----+------------+---------------+------+---------+---------+\n","|Year|Month|MonthlySales|ActiveCustomers|Orders|ItemsSold|MonthYear|\n","+----+-----+------------+---------------+------+---------+---------+\n","|2010|   12|   821452.73|            885|  1629|   361094|  2010-12|\n","|2011|    1|   689811.61|            741|  1120|   397030|  2011-01|\n","|2011|    2|   522545.56|            758|  1126|   286074|  2011-02|\n","|2011|    3|   716215.26|            974|  1531|   384023|  2011-03|\n","|2011|    4|   536968.49|            856|  1318|   311314|  2011-04|\n","|2011|    5|   769296.61|           1056|  1731|   398686|  2011-05|\n","|2011|    6|   760547.01|            991|  1576|   393633|  2011-06|\n","|2011|    7|   718076.12|            949|  1540|   405473|  2011-07|\n","|2011|    8|   757841.38|            935|  1407|   424264|  2011-08|\n","|2011|    9|  1056435.19|           1266|  1896|   574169|  2011-09|\n","|2011|   10|  1151263.73|           1364|  2129|   626373|  2011-10|\n","|2011|   11|  1503866.78|           1665|  2884|   768468|  2011-11|\n","+----+-----+------------+---------------+------+---------+---------+\n","only showing top 12 rows\n","\n","\n","--- TOP 10 CUSTOMERS BY SPENDING ---\n","Top customers:\n","+----------------+--------------+----------+----------+-----------+-------------------+-------------------+\n","|CustomerID_clean|Country       |TotalSpent|TotalItems|TotalOrders|FirstPurchase      |LastPurchase       |\n","+----------------+--------------+----------+----------+-----------+-------------------+-------------------+\n","|14646           |NETHERLANDS   |280206.02 |197491    |74         |2010-12-20 10:09:00|2011-12-08 12:12:00|\n","|18102           |UNITED KINGDOM|259657.3  |64124     |60         |2010-12-07 16:42:00|2011-12-09 11:50:00|\n","|17450           |UNITED KINGDOM|194390.79 |69973     |46         |2010-12-07 09:23:00|2011-12-01 13:29:00|\n","|16446           |UNITED KINGDOM|168472.5  |80997     |2          |2011-05-18 09:52:00|2011-12-09 09:15:00|\n","|14911           |EIRE          |143711.17 |80490     |201        |2010-12-01 14:05:00|2011-12-08 15:54:00|\n","|12415           |AUSTRALIA     |124914.53 |77670     |21         |2011-01-06 11:12:00|2011-11-15 14:22:00|\n","|14156           |EIRE          |117210.08 |57768     |55         |2010-12-03 11:48:00|2011-11-30 10:54:00|\n","|17511           |UNITED KINGDOM|91062.38  |64549     |31         |2010-12-01 10:19:00|2011-12-07 10:12:00|\n","|16029           |UNITED KINGDOM|80850.84  |40108     |63         |2010-12-01 09:57:00|2011-11-01 10:27:00|\n","|12346           |UNITED KINGDOM|77183.6   |74215     |1          |2011-01-18 10:01:00|2011-01-18 10:01:00|\n","+----------------+--------------+----------+----------+-----------+-------------------+-------------------+\n","\n","\n","--- TOP 10 PRODUCTS BY REVENUE ---\n","Top products:\n","+---------+----------------------------------+------------------+---------+-------------+----------+\n","|StockCode|Description                       |Revenue           |UnitsSold|UnitsReturned|OrderCount|\n","+---------+----------------------------------+------------------+---------+-------------+----------+\n","|DOT      |DOTCOM POSTAGE                    |206248.77000000005|708      |0            |708       |\n","|22423    |REGENCY CAKESTAND 3 TIER          |174156.53999999963|13862    |0            |1989      |\n","|23843    |PAPER CRAFT , LITTLE BIRDIE       |168469.6          |80995    |0            |1         |\n","|85123A   |WHITE HANGING HEART T-LIGHT HOLDER|104284.23999999971|37584    |0            |2193      |\n","|47566    |PARTY BUNTING                     |99445.23000000027 |18287    |0            |1686      |\n","|85099B   |JUMBO BAG RED RETROSPOT           |94159.8100000002  |48375    |0            |2092      |\n","|23166    |MEDIUM CERAMIC TOP STORAGE JAR    |81700.92000000006 |78033    |0            |247       |\n","|POST     |POSTAGE                           |78101.88          |3150     |0            |1126      |\n","|M        |MANUAL                            |77750.26999999999 |6990     |0            |294       |\n","|23084    |RABBIT NIGHT LIGHT                |66870.02999999985 |30739    |0            |994       |\n","+---------+----------------------------------+------------------+---------+-------------+----------+\n","\n","\n","Product performance tiers:\n","+---------------+------------+------------+-------------+-----------------+\n","|PerformanceTier|ProductCount|TotalRevenue|AvgReturnRate|ProductPercentage|\n","+---------------+------------+------------+-------------+-----------------+\n","|  Top Performer|         234|   5350496.8|          0.0|             4.08|\n","|  Low Performer|        4069|   707275.19|        27.69|             71.0|\n","| Good Performer|        1428|  4584338.81|          0.0|            24.92|\n","+---------------+------------+------------+-------------+-----------------+\n","\n","\n","--- COUNTRY PERFORMANCE ANALYSIS ---\n","All countries performance:\n","+---------------+------------------+---------+------+\n","|        Country|           Revenue|Customers|Orders|\n","+---------------+------------------+---------+------+\n","| UNITED KINGDOM|  9001744.09399904|     3921| 20120|\n","|    NETHERLANDS| 285446.3399999995|        9|    95|\n","|           EIRE| 283140.5199999988|        3|   288|\n","|        GERMANY|228678.40000000005|       94|   457|\n","|         FRANCE|         209625.37|       87|   392|\n","|      AUSTRALIA|         138453.81|        9|    57|\n","|          SPAIN| 61558.56000000021|       30|    90|\n","|    SWITZERLAND| 57067.60000000012|       21|    54|\n","|        BELGIUM| 41196.34000000001|       25|    98|\n","|         SWEDEN| 38367.82999999999|        8|    36|\n","|          JAPAN| 37416.37000000001|        8|    19|\n","|         NORWAY|36165.439999999995|       10|    36|\n","|       PORTUGAL|33683.049999999945|       19|    58|\n","|        FINLAND|          22546.08|       12|    41|\n","|      SINGAPORE|21279.290000000005|        1|     7|\n","|CHANNEL ISLANDS| 20440.53999999997|        9|    26|\n","|        DENMARK|18955.339999999993|        9|    18|\n","|          ITALY|17483.239999999998|       14|    38|\n","|      HONG KONG|15482.999999999996|        0|    11|\n","|         CYPRUS|13502.850000000004|        8|    16|\n","+---------------+------------------+---------+------+\n","only showing top 20 rows\n","\n","\n","Country insights (Revenue per customer and order):\n","+---------------+------------------+---------+------+------------------+---------------+\n","|        Country|           Revenue|Customers|Orders|RevenuePerCustomer|RevenuePerOrder|\n","+---------------+------------------+---------+------+------------------+---------------+\n","| UNITED KINGDOM|  9001744.09399904|     3921| 20120|           2295.78|          447.4|\n","|    NETHERLANDS| 285446.3399999995|        9|    95|          31716.26|         3004.7|\n","|           EIRE| 283140.5199999988|        3|   288|          94380.17|         983.13|\n","|        GERMANY|228678.40000000005|       94|   457|           2432.75|         500.39|\n","|         FRANCE|         209625.37|       87|   392|           2409.49|         534.76|\n","|      AUSTRALIA|         138453.81|        9|    57|          15383.76|        2429.01|\n","|          SPAIN| 61558.56000000021|       30|    90|           2051.95|         683.98|\n","|    SWITZERLAND| 57067.60000000012|       21|    54|            2717.5|        1056.81|\n","|        BELGIUM| 41196.34000000001|       25|    98|           1647.85|         420.37|\n","|         SWEDEN| 38367.82999999999|        8|    36|           4795.98|        1065.77|\n","|          JAPAN| 37416.37000000001|        8|    19|           4677.05|        1969.28|\n","|         NORWAY|36165.439999999995|       10|    36|           3616.54|         1004.6|\n","|       PORTUGAL|33683.049999999945|       19|    58|           1772.79|         580.74|\n","|        FINLAND|          22546.08|       12|    41|           1878.84|          549.9|\n","|      SINGAPORE|21279.290000000005|        1|     7|          21279.29|         3039.9|\n","|CHANNEL ISLANDS| 20440.53999999997|        9|    26|           2271.17|         786.17|\n","|        DENMARK|18955.339999999993|        9|    18|           2106.15|        1053.07|\n","|          ITALY|17483.239999999998|       14|    38|            1248.8|         460.09|\n","|      HONG KONG|15482.999999999996|        0|    11|              NULL|        1407.55|\n","|         CYPRUS|13502.850000000004|        8|    16|           1687.86|         843.93|\n","+---------------+------------------+---------+------+------------------+---------------+\n","only showing top 20 rows\n","\n","\n","Saving analysis results to /content/retail_output/analysis/...\n","Analysis results saved successfully!\n","\n","==================================================\n","COMPREHENSIVE ANALYSIS COMPLETED!\n","==================================================\n","\n","=== PIPELINE COMPLETED ===\n","Duration: 0:02:24.543462\n","Records processed: 536639\n","\n","============================================================\n","ETL PIPELINE AND ANALYSIS COMPLETED SUCCESSFULLY!\n","============================================================\n","✓ Transformed data saved to: /content/retail_output/transformed_data\n","✓ Summary tables saved to: /content/retail_output/summaries/\n","✓ Analysis results saved to: /content/retail_output/analysis/\n","Spark session stopped.\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPIyHHwTHgiztNpikLx0Cal"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}